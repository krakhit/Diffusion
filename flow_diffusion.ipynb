{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5327a5",
   "metadata": {},
   "source": [
    "# Flow matching and diffusion models\n",
    "\n",
    "Notes based on [An introduction to flow matching and diffusion models](https://arxiv.org/pdf/2506.02070) \n",
    "\n",
    "## Lecture 1\n",
    "\n",
    "### Introduction\n",
    "How does a machine generate something, is it any different from randomly sampling from a given data distribution? How do we create stuff? If I never saw an elephant, would i be able to generate an image of an elephant. Like the five blind men describing an elephant, perhaps one can put together something that approximately looks like an elephant. However in most cases, when we picture an elephant, our brain samples something random based on what we have seen in our past experiences. Indeed, as for machines given a distribution of data (a probability distribution) say $p_{data}$ generation is defined as randomly sampling $z\\sim $p_{data}$. \n",
    "\n",
    "Who knows the complete $p_{data}$? , but perhaps we can define a data set consisting of $N$ samples $z_1,z_2,\\ldots z_N$ sampled from $p_{data}$. Sometimes we want to sample data that satisfies a certain condition $y$, and even this subset of data can have its own conditional probability distribution $p_{data}(\\cdot|y)$. An example would be, sample a dog walking on the street, with the condition that the dog is wearing a red superman cape. The condition here is of course completely arbitrary or user specified, and in principle for each such condition there is a subset of data samples described by a conditional probability distribution. \n",
    "\n",
    "In the context of video generation, we typically use a tensor representation for the sample $z\\in \\mathbb{R}^{f\\times H \\times W\\times c}$ where $f$ is the number of frames (timeframes), $H$ is the height , $W$ is the width and $c$ is the number of channels (for RGB $c=3$). We will also use the notation $d=f\\times H \\times W \\times c$ in the rest of the notes. Given such a representation, we can define video generation as a process by which we start from a initial distribution $p_{init}$, and since we want to randomly sample, a good choice would be to choose $p_{init}\\sim \\mathcal{N}(0,I_d)$ to be a normal distribution with zero mean and unit variance. So any $z\\in p_{init}$ would be totally random, and then all we need to figure out is how to transform this $z$ into $p_{data}$ which would give interpretable $z$. This is the goal of video generation models and is achieved by constructing flow equations that evolve a sample $z\\in p_{init}$ to a sample $z\\in p_{data}$. The evolution is often modelled using a Ordinary Differential Equation (ODE) for flow models, and a Stochastic Differential Equation (SDE) for diffusion models. \n",
    "\n",
    "\n",
    "### Flow models\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
